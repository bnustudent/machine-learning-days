{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apriori是一种常用的数据关联规则挖掘方法，它可以用来找出数据集中频繁出现的数据集合。找出这样的一些频繁集合有利于决策，例如通过找出超市购物车数据的频繁项集，可以更好地设计货架的摆放。需要注意的是它是一种逐层迭代的方法，先找出频繁1项集L1，再利用L1找出频繁2项集，以此类推……"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 关联规则：关联规则是形如 X→Y 的蕴涵表达式，其中X和Y是不相交的项集，即 X∩Y=∅。关联规则的强度可以用它的支持度（support）和置信度（confidence）来度量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持度：$$support(x,y)=p(x,y)=\\frac{num(xy)}{num(allsamples)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "置信度：$$confidence(xy)=p(x|y)=\\frac{p(xy)}{p(y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 最小支持度：最小支持度就是人为规定的阈值，表示项集在统计意义上的最低重要性。 最小置信度：最小置信度也是人为规定的阈值，表示关联规则最低可靠性。 只有支持度与置信度同时达到了最小支持度与最小置信度，此关联规则才会被称为强规则。   \n",
    "  频繁项集：满足最小支持度的所有项集，称作频繁项集。   \n",
    "  频繁项集性质：1、频繁项集的所有非空子集也为频繁项集；2、若A项集不是频繁项集，则其他项集或事务与A项集的并集也不是频繁项集）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：数据集合D，支持度阈值，置信度阈值\n",
    "\n",
    "输出：最大的频繁k项集\n",
    "1）扫描整个数据集，得到所有出现过的数据，作为候选频繁1项集。\n",
    "\n",
    "2）挖掘频繁k项集\n",
    "\n",
    "a) 扫描数据计算候选频繁k项集的支持度\n",
    "\n",
    "b) 去除候选频繁k项集中支持度低于阈值的数据集,得到频繁k项集。如果得到的频繁k项集为空，则直接返回频繁k-1项集的集合作为算法结果，算法结束。如果得到的频繁k项集只有一项，则直接返回频繁k项集的集合作为算法结果，算法结束。\n",
    "\n",
    "c) 基于频繁k项集，连接生成候选频繁k+1项集。\n",
    "\n",
    "3） 令k=k+1，转入步骤2。\n",
    "\n",
    "从算法的步骤可以看出，Aprior算法每轮迭代都要扫描数据集，因此在数据集很大，数据种类很多的时候，算法效率很低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缺点:效率低、占用的内存大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "frequent 1-itemsets\t\tsupport\n",
      "==================================================\n",
      "frozenset({'l2'}) 0.8\n",
      "frozenset({'l3'}) 0.8\n",
      "frozenset({'l4'}) 0.6\n",
      "frozenset({'l1'}) 0.8\n",
      "==================================================\n",
      "frequent 2-itemsets\t\tsupport\n",
      "==================================================\n",
      "frozenset({'l3', 'l1'}) 0.6\n",
      "frozenset({'l2', 'l3'}) 0.6\n",
      "frozenset({'l2', 'l1'}) 0.6\n",
      "frozenset({'l3', 'l4'}) 0.6\n",
      "Big Rules\n",
      "frozenset({'l1'}) => frozenset({'l3'}) conf:  0.7499999999999999\n",
      "frozenset({'l3'}) => frozenset({'l1'}) conf:  0.7499999999999999\n",
      "frozenset({'l3'}) => frozenset({'l2'}) conf:  0.7499999999999999\n",
      "frozenset({'l2'}) => frozenset({'l3'}) conf:  0.7499999999999999\n",
      "frozenset({'l1'}) => frozenset({'l2'}) conf:  0.7499999999999999\n",
      "frozenset({'l2'}) => frozenset({'l1'}) conf:  0.7499999999999999\n",
      "frozenset({'l4'}) => frozenset({'l3'}) conf:  1.0\n",
      "frozenset({'l3'}) => frozenset({'l4'}) conf:  0.7499999999999999\n"
     ]
    }
   ],
   "source": [
    "#数据集\n",
    "def load_data_set():\n",
    "    \"\"\"\n",
    "    将题目中的每个列表写入数据集，返回返回数据集\n",
    "    \"\"\"\n",
    "    data_set = [['l1', 'l2'], ['l1', 'l3', 'l4', 'l5'], ['l2', 'l3', 'l4', 'l6'],\n",
    "            ['l1', 'l2', 'l3', 'l4'], ['l1', 'l2', 'l3','l6']]\n",
    "    return data_set\n",
    "\n",
    "\n",
    "def create_C1(data_set):\n",
    "    \"\"\"\n",
    "    通过扫描数据集创建频繁候选1项集C1。\n",
    "    返回：\n",
    "    C1：包含所有频繁候选1项集的集合\n",
    "    \"\"\"\n",
    "    C1 = set()  # 创建一个空集合，无序不重合\n",
    "    for t in data_set:\n",
    "        for item in t:\n",
    "            item_set = frozenset([item])    #返回一个不可变集合\n",
    "            C1.add(item_set)    #加入到第一项集\n",
    "    return C1\n",
    "\n",
    "\n",
    "def is_apriori(Ck_item, Lksub1):\n",
    "    \"\"\"\n",
    "    判断频繁候选k项集是否满足先验性质。子集是否为频繁项集\n",
    "    参数：\n",
    "    Ck_item：Ck中包含所有频繁项的频繁候选k项集\n",
    "    Lksub1:Lk-1，包含所有频繁候选（k-1）项集的集合。\n",
    "    返回：\n",
    "    真：满足先验属性。\n",
    "    False：不满足Apriori属性。\n",
    "    \"\"\"\n",
    "    for item in Ck_item:\n",
    "        # 判断子集是否在频繁项集里面，不在返回flase，在返回ture\n",
    "        sub_Ck = Ck_item - frozenset([item])\n",
    "        if sub_Ck not in Lksub1:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def create_Ck(Lksub1, k):\n",
    "    \"\"\"\n",
    "    创建Ck，一个包含所有频繁候选k项集的集合\n",
    "    根据k-1的频繁项集连接求出k项集\n",
    "    参数：\n",
    "    Lksub1:包含所有频繁候选（k-1）项集的集合。\n",
    "    len_Lksub1：k-1频繁项集的长度\n",
    "    返回：\n",
    "    Ck：包含所有频繁候选k项集的集合。\n",
    "    \"\"\"\n",
    "    Ck = set()\n",
    "    len_Lksub1 = len(Lksub1)\n",
    "    list_Lksub1 = list(Lksub1)# 集合转换成列表\n",
    "    for i in range(len_Lksub1): #对k-1频繁项集进行连接\n",
    "        for j in range(1, len_Lksub1):\n",
    "            l1 = list(list_Lksub1[i])\n",
    "            l2 = list(list_Lksub1[j])\n",
    "            l1.sort()   #都进行排序，对前k-2项进行比较\n",
    "            l2.sort()\n",
    "            if l1[0:k-2] == l2[0:k-2]:  #前k-2项相等则进行连接\n",
    "                Ck_item = list_Lksub1[i] | list_Lksub1[j]\n",
    "                if is_apriori(Ck_item, Lksub1): #判断子集是否为频繁项集，是则加入到第k项集\n",
    "                    Ck.add(Ck_item)\n",
    "    return Ck\n",
    "\n",
    "\n",
    "def generate_Lk_by_Ck(data_set, Ck, min_support, support_data):\n",
    "    \"\"\"\n",
    "    通过从Ck执行delete策略生成Lk。\n",
    "    参数\n",
    "    Ck：第k项集的集合。\n",
    "    min_support：最小支持度。\n",
    "    item_count:统计ck中每个候选项集出现的次数\n",
    "    support——data：字典。键是frequency itemset(项集)，值是support(支持度)。\n",
    "    t_num:数据集合里面列表的个数\n",
    "    返回：\n",
    "    Lk：包含所有频繁k项集的集合。\n",
    "    \"\"\"\n",
    "    Lk = set()\n",
    "    item_count = {}#空字典\n",
    "    for t in data_set:  #项集里的每个候选频繁项集都要看是否为 数据集里面的每个列表的子集，若是则出现的次数加一\n",
    "        for item in Ck:\n",
    "            if item.issubset(t):    #\n",
    "                if item not in item_count:\n",
    "                    item_count[item] = 1#不在字典中则添加进去，初值为1\n",
    "                else:\n",
    "                    item_count[item] += 1   #已经存在，数值加一\n",
    "    t_num = float(len(data_set))    #求数据集里面多少个列表\n",
    "    # 通过for循环选出满足最小支持度的频繁项集，并添加到support_data\n",
    "    for item in item_count:\n",
    "        if (item_count[item] / t_num) >= min_support:\n",
    "            Lk.add(item)\n",
    "            support_data[item] = item_count[item] / t_num\n",
    "    return Lk\n",
    "\n",
    "\n",
    "def generate_L(data_set, min_support):\n",
    "    \"\"\"\n",
    "    生成所有频繁项集。\n",
    "    参数：\n",
    "    data_set：数据集。\n",
    "    k： 所有频繁项集的最大项数。\n",
    "    min_support：最小支持度。\n",
    "    support_data：字典。键是frequency itemset(频繁项集)，值是support(频繁项集的支持度)。存放频繁所有频繁项集以及它的支持度\n",
    "    c1：所有第一项集\n",
    "    L1:第一频繁项集\n",
    "    LKsub:存放第n项集，然后添加到频繁项集列表L\n",
    "    返回：\n",
    "    L： 频繁项集列表。\n",
    "    \"\"\"\n",
    "    support_data = {}   #空字典\n",
    "    C1 = create_C1(data_set)# 产生所有的第一项集\n",
    "    L1 = generate_Lk_by_Ck(data_set, C1, min_support, support_data)#求第一频繁项集\n",
    "    Lksub1 = L1.copy()  #  Lksub1复制第一频繁项集给频繁项集L\n",
    "    L = []\n",
    "    L.append(Lksub1)    # 添加第一频繁项集\n",
    "    i=2 #第一频繁项集已经求了，根据求出的第一频繁项集求第二项集...频繁项集的子集都是频繁项集\n",
    "    while(1):\n",
    "      Ci = create_Ck(Lksub1, i) #产生第i项集\n",
    "      Li = generate_Lk_by_Ck(data_set, Ci, min_support, support_data)   #产生第i频繁项集\n",
    "      if len(Li)==0:    #当li为空时，更大的也就没有了，调出循环\n",
    "        break\n",
    "      Lksub1 = Li.copy()\n",
    "      L.append(Lksub1)\n",
    "      i+=1\n",
    "    return L, support_data\n",
    "\n",
    "\n",
    "def generate_big_rules(L, support_data, min_conf):\n",
    "    \"\"\"\n",
    "    找出满足最小置信度的频繁项集\n",
    "    参数：\n",
    "    L：频繁项集。\n",
    "    support_data：字典。键是frequency itemset（某频繁项集），值是support（支持度）。频繁项集以及每个项集的支持度\n",
    "    min_conf：最置信度。\n",
    "    返回\n",
    "    满足最小值置信度的频繁项集(强关联规则)\n",
    "    \"\"\"\n",
    "    big_rule_list = []  # 强关联规则的列表\n",
    "    sub_set_list = []   # 子集列表\n",
    "    for i in range(0, len(L)):  # 对于每个频繁项集要产生它的所有非空子集，计算他的置信度，大于最小置信度，则将子集，以及剩下的一些项还有置信度添加到强关联的列表里面\n",
    "        for freq_set in L[i]:   #遍历n频繁项集，第一频繁项集里面没有强关联\n",
    "            for sub_set in sub_set_list:    #频繁项集的子集也一定是频繁项集\n",
    "                if sub_set.issubset(freq_set):  # 判断sub_set是频繁项集的子集\n",
    "                    conf = support_data[freq_set] / support_data[freq_set - sub_set]    #计算置信度\n",
    "                    big_rule = (freq_set - sub_set, sub_set, conf)  #将关联规则以及置信度放入big_rule，如果大于最小置信度则加到强关联规则的列表里面\n",
    "                    if conf >= min_conf and big_rule not in big_rule_list:  #满足最小置信度并之前没有添加\n",
    "                        big_rule_list.append(big_rule)\n",
    "            sub_set_list.append(freq_set)\n",
    "    return big_rule_list\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_set = load_data_set() # 加载数据集\n",
    "    L, support_data = generate_L(data_set, min_support=0.6) # 生成所有频繁项集L，以及含有频繁项集的支持度的字典support_data\n",
    "    big_rules_list = generate_big_rules(L, support_data, min_conf=0.7)  #找出满足最小置信度的频繁项集强关联规则\n",
    "    # 输出频繁项集\n",
    "    for Lk in L:\n",
    "        print(\"=\"*50)\n",
    "        print(\"frequent \" + str(len(list(Lk)[0])) + \"-itemsets\\t\\tsupport\")\n",
    "        print(\"=\"*50)\n",
    "        for freq_set in Lk:\n",
    "            print(freq_set, support_data[freq_set])\n",
    "    print(\"Big Rules\")\n",
    "    # 输出强关联规则\n",
    "    for item in big_rules_list:\n",
    "        print(item[0], \"=>\", item[1], \"conf: \", item[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
